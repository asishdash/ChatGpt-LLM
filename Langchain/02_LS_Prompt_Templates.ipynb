{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asishdash/ChatGpt-LLM/blob/main/Langchain/02_LS_Prompt_Templates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b99d72-d919-4362-a3e9-14e361f231b4",
      "metadata": {
        "tags": [],
        "id": "b5b99d72-d919-4362-a3e9-14e361f231b4"
      },
      "source": [
        "# Understanding Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "SrUbrAxDV1aN"
      },
      "id": "SrUbrAxDV1aN",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "nM8mdv2jV8Hw"
      },
      "id": "nM8mdv2jV8Hw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd1Y74IUV_3h",
        "outputId": "32cdb4f2-25f0-4c88-b40b-bd33a8a20714"
      },
      "id": "zd1Y74IUV_3h",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.263-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
            "  Downloading langsmith-0.0.22-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2,>=1 (from langchain)\n",
            "  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: pydantic, mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langsmith, dataclasses-json, langchain\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.1.1\n",
            "    Uninstalling pydantic-2.1.1:\n",
            "      Successfully uninstalled pydantic-2.1.1\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.263 langsmith-0.0.22 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 pydantic-1.10.12 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA-xoj9JWcem",
        "outputId": "5fb1daf2-8cc8-42ed-aa51-7667c226d88e"
      },
      "id": "AA-xoj9JWcem",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m71.7/73.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bdb72664-ce8d-4d88-b003-8a930ff2c2ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdb72664-ce8d-4d88-b003-8a930ff2c2ab",
        "outputId": "de5f5633-7b00-477b-f06a-5261bd5e9073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "\n",
            "Pluto is actually now classified as a dwarf planet rather than a full-fledged planet.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "api_key=os.environ['OPENAI_API_KEY']\n",
        "llm = OpenAI(openai_api_key=api_key)\n",
        "print(llm('Here is a fun fact about Pluto:'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f579bfe0-103e-430e-bac6-fa9fa50055b5",
      "metadata": {
        "id": "f579bfe0-103e-430e-bac6-fa9fa50055b5"
      },
      "source": [
        "You can also use generate to get full output with more info:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "24db968b-ef5a-4a31-bbb9-a08e48cb0a34",
      "metadata": {
        "id": "24db968b-ef5a-4a31-bbb9-a08e48cb0a34"
      },
      "outputs": [],
      "source": [
        "# NEEDS TO BE A LIST, EVEN FOR JUST ONE STRING\n",
        "result = llm.generate(['Here is a fun fact about Pluto:',\n",
        "                     'Here is a fun fact about Mars:']\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b23e6c06-1543-42a5-94e7-dbb6bf8f4c8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b23e6c06-1543-42a5-94e7-dbb6bf8f4c8e",
        "outputId": "3ec28441-9356-4ae8-bf33-5da1753b23ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'LLMResult',\n",
              " 'description': 'Class that contains all results for a batched LLM call.',\n",
              " 'type': 'object',\n",
              " 'properties': {'generations': {'title': 'Generations',\n",
              "   'type': 'array',\n",
              "   'items': {'type': 'array', 'items': {'$ref': '#/definitions/Generation'}}},\n",
              "  'llm_output': {'title': 'Llm Output', 'type': 'object'},\n",
              "  'run': {'title': 'Run',\n",
              "   'type': 'array',\n",
              "   'items': {'$ref': '#/definitions/RunInfo'}}},\n",
              " 'required': ['generations'],\n",
              " 'definitions': {'Generation': {'title': 'Generation',\n",
              "   'description': 'A single text generation output.',\n",
              "   'type': 'object',\n",
              "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
              "    'generation_info': {'title': 'Generation Info', 'type': 'object'}},\n",
              "   'required': ['text']},\n",
              "  'RunInfo': {'title': 'RunInfo',\n",
              "   'description': 'Class that contains metadata for a single execution of a Chain or model.',\n",
              "   'type': 'object',\n",
              "   'properties': {'run_id': {'title': 'Run Id',\n",
              "     'type': 'string',\n",
              "     'format': 'uuid'}},\n",
              "   'required': ['run_id']}}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "result.schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f6575b5-3331-4ec6-9281-8f793ab541dc",
      "metadata": {
        "id": "9f6575b5-3331-4ec6-9281-8f793ab541dc"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38d37ccf-99d2-4aa6-ab73-0bd22e55b7b6",
      "metadata": {
        "tags": [],
        "id": "38d37ccf-99d2-4aa6-ab73-0bd22e55b7b6"
      },
      "source": [
        "## Language Model Templates\n",
        "\n",
        "### No Input Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1e34d990-cc7c-47f6-a191-854a575aabca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1e34d990-cc7c-47f6-a191-854a575aabca",
        "outputId": "6ec8a098-e148-4b8a-91c3-65347159b713"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a fact'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "# An example prompt with no input variables\n",
        "no_input_prompt = PromptTemplate(input_variables=[], template=\"Tell me a fact\")\n",
        "no_input_prompt.format()\n",
        "# -> \"Tell me a fact.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be521325-8963-4505-8bf3-83b05e8a796a",
      "metadata": {
        "id": "be521325-8963-4505-8bf3-83b05e8a796a"
      },
      "source": [
        "### Single Input Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "361467f3-81d3-4553-9a22-1198f44598c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "361467f3-81d3-4553-9a22-1198f44598c0",
        "outputId": "89c664aa-6533-42d6-d119-2265c0c4bf18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a fact about Mars.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# An example prompt with one input variable\n",
        "one_input_prompt = PromptTemplate(input_variables=[\"topic\"], template=\"Tell me a fact about {topic}.\")\n",
        "# Notice how the stirng \"topic\" gets automatically converted to a parameter name, very convienent!\n",
        "one_input_prompt.format(topic=\"Mars\")\n",
        "# -> \"Tell me a fact about Mars\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3e8c513-b8d0-4616-9015-e0133cfc45d4",
      "metadata": {
        "id": "e3e8c513-b8d0-4616-9015-e0133cfc45d4"
      },
      "source": [
        "### Multiple Input Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "aba25263-4b12-40d8-8c56-e21b9bc37891",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aba25263-4b12-40d8-8c56-e21b9bc37891",
        "outputId": "16b18b3f-07e5-479f-c619-1e50e966569f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a fact about Mars for a student 8th Grade level.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# An example prompt with multiple input variables\n",
        "multiple_input_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\", \"level\"],\n",
        "    template=\"Tell me a fact about {topic} for a student {level} level.\"\n",
        ")\n",
        "multiple_input_prompt.format(topic='Mars',level='8th Grade')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61d47473-7d74-4bbf-875e-898bc9cdb1ec",
      "metadata": {
        "id": "61d47473-7d74-4bbf-875e-898bc9cdb1ec"
      },
      "source": [
        "# Chat Model Templates\n",
        "\n",
        "Chat models require a list of chat messages called a prompt, which is different from a raw string that you would input into a language model. Each message in the prompt is associated with a role, such as AI, human, or system.\n",
        "\n",
        "For instance, when using the OpenAI Chat Completion API, a chat message can be assigned the role of AI, human, or system. The model is designed to pay closer attention to instructions provided in system chat messages.\n",
        "\n",
        "To simplify the process of constructing and working with prompts, LangChain offers various prompt templates. It is highly recommended to utilize these chat-related prompt templates instead of PromptTemplate when interacting with chat models. This will allow you to fully harness the potential of the underlying chat model and enhance your experience.\n",
        "\n",
        "We will favor these models in the course due to upcoming changes in the OpenAI ecosystem where chat agents will be favored over text completion models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "923b8070-19ab-4972-89f0-57b6e56053fb",
      "metadata": {
        "id": "923b8070-19ab-4972-89f0-57b6e56053fb"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cbc8eeab-11ff-4c46-b69b-e963066980d0",
      "metadata": {
        "id": "cbc8eeab-11ff-4c46-b69b-e963066980d0"
      },
      "outputs": [],
      "source": [
        "system_template=\"You are an AI recipe assistant that specializes in {dietary_preference} dishes that can be prepared in {cooking_time}.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d93298f9-18d3-43af-bc23-633f5f3ab269",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d93298f9-18d3-43af-bc23-633f5f3ab269",
        "outputId": "5ab32747-ba82-40a7-f68c-768066141c01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cooking_time', 'dietary_preference']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "system_message_prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2348e5e3-e878-403a-94e9-be61359fbb44",
      "metadata": {
        "id": "2348e5e3-e878-403a-94e9-be61359fbb44"
      },
      "outputs": [],
      "source": [
        "human_template=\"{recipe_request}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d01b14b6-f422-4a08-bd0e-bba0f494563d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d01b14b6-f422-4a08-bd0e-bba0f494563d",
        "outputId": "984ef8cf-21ba-4697-ee86-e5202efca82c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['recipe_request']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "human_message_prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "706756df-1264-4121-8043-b733e60188c0",
      "metadata": {
        "id": "706756df-1264-4121-8043-b733e60188c0"
      },
      "outputs": [],
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "52fdf3cf-f3d9-4108-ae72-b630487d9e9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52fdf3cf-f3d9-4108-ae72-b630487d9e9b",
        "outputId": "e2cbf9e2-03c3-440f-faf6-7a8485b8ef7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cooking_time', 'dietary_preference', 'recipe_request']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "chat_prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3b19ae01-3be8-41c9-a470-3fd6fc69e801",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b19ae01-3be8-41c9-a470-3fd6fc69e801",
        "outputId": "60c30f93-18d3-45eb-aac9-0b2d875a2ebd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are an AI recipe assistant that specializes in Vegan dishes that can be prepared in 15 min.', additional_kwargs={}),\n",
              " HumanMessage(content='Quick Snack', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# get a chat completion from the formatted messages\n",
        "chat_prompt.format_prompt(cooking_time=\"15 min\", dietary_preference=\"Vegan\", recipe_request=\"Quick Snack\").to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "73121537-8cee-42fc-ba0e-fc1c18154957",
      "metadata": {
        "id": "73121537-8cee-42fc-ba0e-fc1c18154957"
      },
      "outputs": [],
      "source": [
        "request = chat_prompt.format_prompt(cooking_time=\"15 min\", dietary_preference=\"Vegan\", recipe_request=\"Quick Snack\").to_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c276622f-d81c-40ed-864b-63d4c4311d84",
      "metadata": {
        "id": "c276622f-d81c-40ed-864b-63d4c4311d84"
      },
      "source": [
        "## Prompt Templates with an LLM Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d21e33e-6ce1-4391-b406-279af06510f2",
      "metadata": {
        "id": "0d21e33e-6ce1-4391-b406-279af06510f2"
      },
      "outputs": [],
      "source": [
        "#f = open('C:\\\\Users\\\\Marcial\\\\Desktop\\\\desktop_openai.txt')\n",
        "#api_key = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c1496d66-efec-4cd5-a62e-d33f9669941c",
      "metadata": {
        "id": "c1496d66-efec-4cd5-a62e-d33f9669941c"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "chat = ChatOpenAI(openai_api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8978391d-9c09-4b99-8520-27491ece4e9d",
      "metadata": {
        "id": "8978391d-9c09-4b99-8520-27491ece4e9d"
      },
      "outputs": [],
      "source": [
        "result = chat(request)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "88f47c1b-123c-4f47-8ee1-b72c88cbd048",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88f47c1b-123c-4f47-8ee1-b72c88cbd048",
        "outputId": "13639d39-4e4a-4cff-f9ae-d26240c441a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Here's a quick and easy vegan snack recipe that you can prepare in just 15 minutes:\\n\\nVegan Hummus and Veggie Wrap\\n\\nIngredients:\\n- 1 large whole wheat tortilla or wrap\\n- 1/2 cup of hummus (store-bought or homemade)\\n- 1/4 cup of sliced cucumbers\\n- 1/4 cup of shredded carrots\\n- 1/4 cup of sliced bell peppers\\n- Handful of baby spinach or lettuce\\n- Salt and pepper to taste\\n\\nInstructions:\\n1. Lay the tortilla or wrap flat on a clean surface.\\n2. Spread the hummus evenly over the tortilla, leaving about an inch around the edges.\\n3. Layer the sliced cucumbers, shredded carrots, bell peppers, and baby spinach on top of the hummus.\\n4. Sprinkle with a pinch of salt and pepper to taste.\\n5. Roll the tortilla tightly, pressing down gently as you go to secure the ingredients.\\n6. Cut the wrap into bite-sized pieces, and it's ready to serve!\\n\\nThis hummus and veggie wrap is not only delicious but also packed with nutrients and fiber. Enjoy it as a quick snack or pack it for a light lunch on the go.\", additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6ae9e58d-00b9-4ba4-af37-9ff35a4bef9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ae9e58d-00b9-4ba4-af37-9ff35a4bef9f",
        "outputId": "4ede6d4b-1ea9-4822-8edc-a1cb82f54353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a quick and easy vegan snack recipe that you can prepare in just 15 minutes:\n",
            "\n",
            "Vegan Hummus and Veggie Wrap\n",
            "\n",
            "Ingredients:\n",
            "- 1 large whole wheat tortilla or wrap\n",
            "- 1/2 cup of hummus (store-bought or homemade)\n",
            "- 1/4 cup of sliced cucumbers\n",
            "- 1/4 cup of shredded carrots\n",
            "- 1/4 cup of sliced bell peppers\n",
            "- Handful of baby spinach or lettuce\n",
            "- Salt and pepper to taste\n",
            "\n",
            "Instructions:\n",
            "1. Lay the tortilla or wrap flat on a clean surface.\n",
            "2. Spread the hummus evenly over the tortilla, leaving about an inch around the edges.\n",
            "3. Layer the sliced cucumbers, shredded carrots, bell peppers, and baby spinach on top of the hummus.\n",
            "4. Sprinkle with a pinch of salt and pepper to taste.\n",
            "5. Roll the tortilla tightly, pressing down gently as you go to secure the ingredients.\n",
            "6. Cut the wrap into bite-sized pieces, and it's ready to serve!\n",
            "\n",
            "This hummus and veggie wrap is not only delicious but also packed with nutrients and fiber. Enjoy it as a quick snack or pack it for a light lunch on the go.\n"
          ]
        }
      ],
      "source": [
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a72ee656-ec4b-4c5b-b839-1b3c2f269f07",
      "metadata": {
        "id": "a72ee656-ec4b-4c5b-b839-1b3c2f269f07"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}